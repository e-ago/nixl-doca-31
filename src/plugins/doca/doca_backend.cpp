/*
 * SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#include "doca_backend.h"
#include "serdes/serdes.h"
#include <cassert>
#include <stdexcept>
#include <arpa/inet.h>
#include <unistd.h>

DOCA_LOG_REGISTER(NIXL::DOCA);

/****************************************
 * DOCA request management
*****************************************/

static void nixlDocaEngineCheckCudaError(cudaError_t result, const char *message) {
	if (result != cudaSuccess) {
		std::cerr << message << " (Error code: " << result << " - "
				   << cudaGetErrorString(result) << ")" << std::endl;
		exit(EXIT_FAILURE);
	}
}

static int oob_connection_client_setup(const char *server_ip, int *oob_sock_fd)
{
	struct sockaddr_in server_addr = {0};
	int oob_sock_fd_;

	/* Create socket */
	oob_sock_fd_ = socket(AF_INET, SOCK_STREAM, 0);
	if (oob_sock_fd_ < 0) {
		DOCA_LOG_ERR("Unable to create socket");
		return -1;
	}
	DOCA_LOG_INFO("Socket created successfully");

	/* Set port and IP the same as server-side: */
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(DOCA_RDMA_CM_LOCAL_PORT_SERVER);
	server_addr.sin_addr.s_addr = inet_addr(server_ip);

	/* Send connection request to server: */
	if (connect(oob_sock_fd_, (struct sockaddr *)&server_addr, sizeof(server_addr)) < 0) {
		close(oob_sock_fd_);
		DOCA_LOG_ERR("Unable to connect to server at %s", server_ip);
		return -1;
	}
	DOCA_LOG_INFO("Connected with server successfully");

	*oob_sock_fd = oob_sock_fd_;
	return 0;
}

static void oob_connection_client_close(int oob_sock_fd)
{
	if (oob_sock_fd > 0)
		close(oob_sock_fd);
}

static void oob_connection_server_close(int oob_sock_fd) //, int oob_sock_client)
{
	// if (oob_sock_client > 0)
	// 	close(oob_sock_client);

	if (oob_sock_fd > 0) {
		shutdown(oob_sock_fd, SHUT_RDWR);
		close(oob_sock_fd);
	}
}

nixl_status_t nixlDocaEngine::nixlDocaInitNotif(const std::string &remote_agent, struct doca_dev *dev, struct doca_gpu *gpu)
{
	doca_error_t result;
	struct nixlDocaNotif *notif;
	// cudaError_t err;

	//Same peer can be server or client
	if(notifMap.find(remote_agent) != notifMap.end()) {
		return NIXL_SUCCESS;
	}

	notif = new struct nixlDocaNotif;

	notif->elems_num = DOCA_MAX_NOTIF_INFLIGHT;
	notif->elems_size = DOCA_MAX_NOTIF_MESSAGE_SIZE;
	notif->send_addr = (uint8_t *)calloc(notif->elems_size * notif->elems_num, sizeof(uint8_t));
	if (notif->send_addr == nullptr) {
		DOCA_LOG_ERR("Can't alloc memory for send notif");
		return NIXL_ERR_BACKEND;
	}
	memset(notif->send_addr, 0, notif->elems_size * notif->elems_num);

	{
		result = doca_mmap_create(&(notif->send_mmap));
		if (result != DOCA_SUCCESS)
			return NIXL_ERR_BACKEND;

		result = doca_mmap_set_permissions(notif->send_mmap,
					DOCA_ACCESS_FLAG_LOCAL_READ_WRITE | DOCA_ACCESS_FLAG_RDMA_WRITE | DOCA_ACCESS_FLAG_PCI_RELAXED_ORDERING);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_mmap_set_memrange(notif->send_mmap, (void*)notif->send_addr, (size_t)notif->elems_num * notif->elems_size);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_mmap_add_dev(notif->send_mmap, dev);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_mmap_start(notif->send_mmap);
		if (result != DOCA_SUCCESS)
			goto error;
	}

	{
		/* Local buffer array */
		result = doca_buf_arr_create(notif->elems_num, &(notif->send_barr));
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_set_params(notif->send_barr, notif->send_mmap, (size_t)notif->elems_size, 0);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_set_target_gpu(notif->send_barr, gpu);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_start(notif->send_barr);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_get_gpu_handle(notif->send_barr, &(notif->send_barr_gpu));
		if (result != DOCA_SUCCESS)
			goto error;
	}

	notif->recv_addr = (uint8_t *)calloc(notif->elems_size * notif->elems_num, sizeof(uint8_t));
	if (notif->recv_addr == nullptr) {
		DOCA_LOG_ERR("Can't alloc memory for send notif");
		return NIXL_ERR_BACKEND;
	}
	memset(notif->recv_addr, 0, notif->elems_size * notif->elems_num);

	{
		result = doca_mmap_create(&(notif->recv_mmap));
		if (result != DOCA_SUCCESS)
			return NIXL_ERR_BACKEND;

		result = doca_mmap_set_permissions(notif->recv_mmap,
					DOCA_ACCESS_FLAG_LOCAL_READ_WRITE | DOCA_ACCESS_FLAG_RDMA_WRITE | DOCA_ACCESS_FLAG_PCI_RELAXED_ORDERING);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_mmap_set_memrange(notif->recv_mmap, (void*)notif->recv_addr, (size_t)notif->elems_num * notif->elems_size);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_mmap_add_dev(notif->recv_mmap, dev);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_mmap_start(notif->recv_mmap);
		if (result != DOCA_SUCCESS)
			goto error;
	}

	{
		/* Local buffer array */
		result = doca_buf_arr_create(notif->elems_num, &(notif->recv_barr));
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_set_params(notif->recv_barr, notif->recv_mmap, (size_t)notif->elems_size, 0);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_set_target_gpu(notif->recv_barr, gpu);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_start(notif->recv_barr);
		if (result != DOCA_SUCCESS)
			goto error;

		result = doca_buf_arr_get_gpu_handle(notif->recv_barr, &(notif->recv_barr_gpu));
		if (result != DOCA_SUCCESS)
			goto error;
	}

	notif->send_pi = 0;
	notif->recv_pi = 0;

	notifLock.lock();

	notifMap[remote_agent] = notif;
	((volatile struct docaNotifRecv *)notif_fill_cpu)->rdma_qp = qpMap[remote_agent]->rdma_gpu_notif;
	((volatile struct docaNotifRecv *)notif_fill_cpu)->barr_gpu = notif->recv_barr_gpu;
	while (((volatile struct docaNotifRecv *)notif_fill_cpu)->rdma_qp != nullptr);

	notifLock.unlock();

	return NIXL_SUCCESS;

error:
	if (notif->send_barr)
		doca_buf_arr_destroy(notif->send_barr);	
	if (notif->recv_barr)
		doca_buf_arr_destroy(notif->recv_barr);

	if (notif->send_mmap)
		doca_mmap_destroy(notif->send_mmap);
	if (notif->recv_mmap)
		doca_mmap_destroy(notif->recv_mmap);

	return NIXL_ERR_BACKEND;
}

nixl_status_t nixlDocaEngine::nixlDocaDestroyNotif(struct doca_gpu *gpu, struct nixlDocaNotif *notif) {

	if (notif->send_barr)
		doca_buf_arr_destroy(notif->send_barr);
	if (notif->recv_barr)
		doca_buf_arr_destroy(notif->recv_barr);

	if (notif->send_mmap)
		doca_mmap_destroy(notif->send_mmap);
	if (notif->recv_mmap)
		doca_mmap_destroy(notif->recv_mmap);

	return NIXL_SUCCESS;
}

void nixlDocaEngine::_requestInit(void *request)
{
	/* Initialize request in-place (aka "placement new")*/
	new(request) nixlDocaBckndReq;
}

void nixlDocaEngine::_requestFini(void *request)
{
	/* Finalize request */
	nixlDocaBckndReq *req = (nixlDocaBckndReq*)request;
	req->~nixlDocaBckndReq();
}

static doca_error_t
open_doca_device_with_ibdev_name(const uint8_t *value, size_t val_size, struct doca_dev **retval)
{
	struct doca_devinfo **dev_list;
	uint32_t nb_devs;
	char buf[DOCA_DEVINFO_IBDEV_NAME_SIZE] = {};
	char val_copy[DOCA_DEVINFO_IBDEV_NAME_SIZE] = {};
	doca_error_t res;
	size_t i;

	/* Set default return value */
	*retval = NULL;

	/* Setup */
	if (val_size > DOCA_DEVINFO_IBDEV_NAME_SIZE) {
		DOCA_LOG_ERR("Value size too large. Failed to locate device");
		return DOCA_ERROR_INVALID_VALUE;
	}
	memcpy(val_copy, value, val_size);

	res = doca_devinfo_create_list(&dev_list, &nb_devs);
	if (res != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to load doca devices list. Doca_error value");
		return res;
	}

	/* Search */
	for (i = 0; i < nb_devs; i++) {
		res = doca_devinfo_get_ibdev_name(dev_list[i], buf, DOCA_DEVINFO_IBDEV_NAME_SIZE);
		if (res == DOCA_SUCCESS && strncmp(buf, val_copy, val_size) == 0) {
			/* If any special capabilities are needed */
			/* if device can be opened */
			res = doca_dev_open(dev_list[i], retval);
			if (res == DOCA_SUCCESS) {
				doca_devinfo_destroy_list(dev_list);
				return res;
			}
		}
	}

	DOCA_LOG_ERR("Matching device not found");

	res = DOCA_ERROR_NOT_FOUND;

	doca_devinfo_destroy_list(dev_list);
	return res;
}

/****************************************
 * Progress thread management
*****************************************/

// void nixlDocaEngine::progressFunc(void *arg)
void * progressFunc(void *arg)
{
    using namespace nixlTime;
	struct sockaddr_in client_addr = {0};
	unsigned int client_size = 0;
	size_t msg_size;
	char *remote_agent;
	int oob_sock_client;

	nixlDocaEngine *eng = (nixlDocaEngine *)arg;

	eng->pthrActive = 1;

	while (ACCESS_ONCE(eng->pthrStop) == 0) {
		/* Accept an incoming connection: */
		client_size = sizeof(client_addr);
		oob_sock_client = accept(eng->oob_sock_server, (struct sockaddr *)&client_addr, &client_size);
		if (oob_sock_client < 0) {
			DOCA_LOG_ERR("Can't accept new socket connection %d", oob_sock_client);
			close(eng->oob_sock_server);
			return NULL;
		}

		DOCA_LOG_INFO("Client connected at IP: %s and port: %i",
				inet_ntoa(client_addr.sin_addr),
				ntohs(client_addr.sin_port));

		// Msg
		if (recv(oob_sock_client, &msg_size, sizeof(size_t), 0) < 0) {
			DOCA_LOG_ERR("Failed to recv msg details");
			close(oob_sock_client);
		}

		remote_agent = (char *)calloc(msg_size, sizeof(char));
		if (remote_agent == nullptr) {
			DOCA_LOG_ERR("Failed to alloc msg memory");
			close(oob_sock_client);
		}

		if (recv(oob_sock_client, remote_agent, msg_size, 0) < 0) {
			DOCA_LOG_ERR("Failed to recv msg details");
			close(oob_sock_client);
		}

		cuCtxSetCurrent(eng->main_cuda_ctx);
		eng->addRdmaQp(remote_agent);
		eng->nixlDocaInitNotif(remote_agent, eng->ddev, eng->gdevs[0].second);
		eng->connectServerRdmaQp(oob_sock_client, remote_agent);

		/* Wait for predefined number of */
		nixlTime::us_t start = nixlTime::getUs();
		while( (start + DOCA_RDMA_SERVER_CONN_DELAY) > nixlTime::getUs()) {
			std::this_thread::yield();
		}
	}

	return NULL;
}

void nixlDocaEngine::progressThreadStart()
{
	struct sockaddr_in server_addr = {0};
	int enable = 1;
	int result;
    pthrStop = pthrActive = 0;
    noSyncIters = 32;

	/* Create socket */


	oob_sock_server = socket(AF_INET, SOCK_STREAM, 0);
	if (oob_sock_server < 0) {
		DOCA_LOG_ERR("Error while creating socket %d", oob_sock_server);
		return;
	}
	DOCA_LOG_INFO("Socket created successfully");

	if (setsockopt(oob_sock_server, SOL_SOCKET, SO_REUSEPORT, &enable, sizeof(enable))) {
		DOCA_LOG_ERR("Error setting socket options");
		close(oob_sock_server);
		return;
	}

	if (setsockopt(oob_sock_server, SOL_SOCKET, SO_REUSEADDR, &enable, sizeof(enable))) {
		DOCA_LOG_ERR("Error setting socket options");
		close(oob_sock_server);
		return;
	}
	/* Set port and IP: */
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(DOCA_RDMA_CM_LOCAL_PORT_SERVER);
	server_addr.sin_addr.s_addr = INADDR_ANY; /* listen on any interface */

	/* Bind to the set port and IP: */
	if (bind(oob_sock_server, (struct sockaddr *)&server_addr, sizeof(server_addr)) < 0) {
		DOCA_LOG_ERR("Couldn't bind to the port");
		close(oob_sock_server);
		return;
	}
	DOCA_LOG_INFO("Done with binding");

	/* Listen for clients: */
	if (listen(oob_sock_server, 1) < 0) {
		DOCA_LOG_ERR("Error while listening");
		close(oob_sock_server);
		return;
	}
	DOCA_LOG_INFO("Listening for incoming connections");

    // Start the thread
    // TODO [Relaxed mem] mem barrier to ensure pthr_x updates are complete
    // new (&pthr) std::thread(&nixlDocaEngine::progressFunc, this);

	result = pthread_create(&server_thread_id, NULL, progressFunc, (void *)this);
	if (result != 0) {
		perror("Failed to create thread");
	}

    // Wait for the thread to be started
    // while(!pthrActive){
    //     std::this_thread::sleep_for(std::chrono::milliseconds(1));
    // }
}

void nixlDocaEngine::progressThreadStop()
{
    ACCESS_ONCE(pthrStop) = 1;
    // pthr.join();
	pthread_join(server_thread_id, NULL);
}

void nixlDocaEngine::progressThreadRestart()
{
    // progressThreadStop();
    // progressThreadStart();
}

uint32_t nixlDocaEngine::getGpuCudaId()
{
	return gdevs[0].first;
}

nixl_status_t nixlDocaEngine::addRdmaQp(const std::string &remote_agent) {
	doca_error_t result;
	struct nixlDocaRdmaQp *rdma_qp;

	//Same peer can be server or client
	if(qpMap.find(remote_agent) != qpMap.end()) {
		return NIXL_SUCCESS;
	}

	rdma_qp = new struct nixlDocaRdmaQp;

	/* DATA QP */

	/* Create DOCA RDMA instance */
	result = doca_rdma_create(ddev, &(rdma_qp->rdma_data));
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to create DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Convert DOCA RDMA to general DOCA context */
	rdma_qp->rdma_ctx_data = doca_rdma_as_ctx(rdma_qp->rdma_data);
	if (rdma_qp->rdma_ctx_data == NULL) {
		result = DOCA_ERROR_UNEXPECTED;
		DOCA_LOG_ERR("Failed to convert DOCA RDMA to DOCA context: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Set permissions to DOCA RDMA */
	result = doca_rdma_set_permissions(rdma_qp->rdma_data, DOCA_ACCESS_FLAG_LOCAL_READ_WRITE | DOCA_ACCESS_FLAG_RDMA_WRITE);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set permissions to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	// /* Set gid_index to DOCA RDMA if it's provided */
	// if (cfg->is_gid_index_set) {
	// 	/* Set gid_index to DOCA RDMA */
	// 	result = doca_rdma_set_gid_index(rdma, cfg->gid_index);
	// 	if (result != DOCA_SUCCESS) {
	// 		DOCA_LOG_ERR("Failed to set gid_index to DOCA RDMA: %s", doca_error_get_descr(result));
	// return NIXL_ERR_BACKEND;
	// 	}
	// }

	/* Set send queue size to DOCA RDMA */
	result = doca_rdma_set_send_queue_size(rdma_qp->rdma_data, RDMA_SEND_QUEUE_SIZE);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set send queue size to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Setup datapath of RDMA CTX on GPU */
	result = doca_ctx_set_datapath_on_gpu(rdma_qp->rdma_ctx_data, gdevs[0].second);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set datapath on GPU: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Set receive queue size to DOCA RDMA */
	result = doca_rdma_set_recv_queue_size(rdma_qp->rdma_data, RDMA_RECV_QUEUE_SIZE);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set receive queue size to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Set GRH to DOCA RDMA */
	result = doca_rdma_set_grh_enabled(rdma_qp->rdma_data, true);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set GRH to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	result = doca_ctx_start(rdma_qp->rdma_ctx_data);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to start RDMA context data: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	result = doca_rdma_get_gpu_handle(rdma_qp->rdma_data, &(rdma_qp->rdma_gpu_data));
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to get RDMA GPU handler: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	result = doca_rdma_export(rdma_qp->rdma_data,
					  &(rdma_qp->connection_details_data),
					  &(rdma_qp->conn_det_len_data),
					  &rdma_qp->connection_data);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to export RDMA handler: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* NOTIF QP */

	/* Create DOCA RDMA instance */
	result = doca_rdma_create(ddev, &(rdma_qp->rdma_notif));
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to create DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Convert DOCA RDMA to general DOCA context */
	rdma_qp->rdma_ctx_notif = doca_rdma_as_ctx(rdma_qp->rdma_notif);
	if (rdma_qp->rdma_ctx_notif == NULL) {
		result = DOCA_ERROR_UNEXPECTED;
		DOCA_LOG_ERR("Failed to convert DOCA RDMA to DOCA context: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Set permissions to DOCA RDMA */
	result = doca_rdma_set_permissions(rdma_qp->rdma_notif, DOCA_ACCESS_FLAG_LOCAL_READ_WRITE | DOCA_ACCESS_FLAG_RDMA_WRITE);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set permissions to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	// /* Set gid_index to DOCA RDMA if it's provided */
	// if (cfg->is_gid_index_set) {
	// 	/* Set gid_index to DOCA RDMA */
	// 	result = doca_rdma_set_gid_index(rdma, cfg->gid_index);
	// 	if (result != DOCA_SUCCESS) {
	// 		DOCA_LOG_ERR("Failed to set gid_index to DOCA RDMA: %s", doca_error_get_descr(result));
	// return NIXL_ERR_BACKEND;
	// 	}
	// }

	/* Set send queue size to DOCA RDMA */
	result = doca_rdma_set_send_queue_size(rdma_qp->rdma_notif, RDMA_SEND_QUEUE_SIZE);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set send queue size to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Setup notifpath of RDMA CTX on GPU */
	result = doca_ctx_set_datapath_on_gpu(rdma_qp->rdma_ctx_notif, gdevs[0].second);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set notifpath on GPU: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Set receive queue size to DOCA RDMA */
	result = doca_rdma_set_recv_queue_size(rdma_qp->rdma_notif, RDMA_RECV_QUEUE_SIZE);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set receive queue size to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Set GRH to DOCA RDMA */
	result = doca_rdma_set_grh_enabled(rdma_qp->rdma_notif, true);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to set GRH to DOCA RDMA: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	result = doca_ctx_start(rdma_qp->rdma_ctx_notif);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to start RDMA context notif: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	result = doca_rdma_get_gpu_handle(rdma_qp->rdma_notif, &(rdma_qp->rdma_gpu_notif));
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to get RDMA GPU handler: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	result = doca_rdma_export(rdma_qp->rdma_notif,
					  &(rdma_qp->connection_details_notif),
					  &(rdma_qp->conn_det_len_notif),
					  &rdma_qp->connection_notif);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Failed to export RDMA handler: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	qpMap[remote_agent] = rdma_qp;

	DOCA_LOG_INFO("New QP added for %s\n", remote_agent.c_str());

	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::connectClientRdmaQp(int oob_sock_client, const std::string &remote_agent) {
	doca_error_t result;
	void *remote_conn_details_data = NULL;
	void *remote_conn_details_notif = NULL;
	size_t remote_conn_details_len_data = 0;
	size_t remote_conn_details_len_notif = 0;
	struct nixlDocaRdmaQp *rdma_qp = qpMap[remote_agent]; //validate 

	printf("Connected to server\n");
	
	//Data QP
	if (send(oob_sock_client, &rdma_qp->conn_det_len_data, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (send(oob_sock_client, rdma_qp->connection_details_data, rdma_qp->conn_det_len_data, 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	//Notif QP
	if (send(oob_sock_client, &rdma_qp->conn_det_len_notif, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (send(oob_sock_client, rdma_qp->connection_details_notif, rdma_qp->conn_det_len_notif, 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	DOCA_LOG_ERR("Receive remote data qp connection details");
	if (recv(oob_sock_client, &remote_conn_details_len_data, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (remote_conn_details_len_data <= 0 || remote_conn_details_len_data >= (size_t)-1) {
		DOCA_LOG_ERR("Received wrong remote connection details");
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	remote_conn_details_data = calloc(1, remote_conn_details_len_data);
	if (remote_conn_details_data == NULL) {
		DOCA_LOG_ERR("Failed to allocate memory for remote connection details");
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	if (recv(oob_sock_client, remote_conn_details_data, remote_conn_details_len_data, 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	DOCA_LOG_INFO("Receive remote notif qp connection details");
	if (recv(oob_sock_client, &remote_conn_details_len_notif, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (remote_conn_details_len_notif <= 0 || remote_conn_details_len_notif >= (size_t)-1) {
		DOCA_LOG_ERR("Received wrong remote connection details");
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	remote_conn_details_notif = calloc(1, remote_conn_details_len_notif);
	if (remote_conn_details_notif == NULL) {
		DOCA_LOG_ERR("Failed to allocate memory for remote connection details");
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	if (recv(oob_sock_client, remote_conn_details_notif, remote_conn_details_len_notif, 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	/* Connect local rdma to the remote rdma */
	DOCA_LOG_INFO("Connect DOCA RDMA to remote RDMA -- data");
	result = doca_rdma_connect(rdma_qp->rdma_data, remote_conn_details_data, remote_conn_details_len_data, rdma_qp->connection_data);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Function doca_rdma_connect failed: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	free(remote_conn_details_data);
	remote_conn_details_data = NULL;

	/* Connect local rdma to the remote rdma */
	DOCA_LOG_INFO("Connect DOCA RDMA to remote RDMA -- notif");
	result = doca_rdma_connect(rdma_qp->rdma_notif, remote_conn_details_notif, remote_conn_details_len_notif, rdma_qp->connection_notif);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Function doca_rdma_connect failed: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	free(remote_conn_details_notif);
	remote_conn_details_notif = NULL;

	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::connectServerRdmaQp(int oob_sock_client, const std::string &remote_agent) {
	doca_error_t result;
	void *remote_conn_details_data = NULL;
	size_t remote_conn_details_data_len = 0;
	void *remote_conn_details_notif = NULL;
	size_t remote_conn_details_notif_len = 0;

	struct nixlDocaRdmaQp *rdma_qp = qpMap[remote_agent]; //validate 

	if (recv(oob_sock_client, &remote_conn_details_data_len, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (remote_conn_details_data_len <= 0 || remote_conn_details_data_len >= (size_t)-1) {
		DOCA_LOG_ERR("Received wrong remote connection details");
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	remote_conn_details_data = calloc(1, remote_conn_details_data_len);
	if (remote_conn_details_data == NULL) {
		DOCA_LOG_ERR("Failed to allocate memory for remote data details %zd",
				remote_conn_details_data_len);
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	if (recv(oob_sock_client, remote_conn_details_data, remote_conn_details_data_len, 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (recv(oob_sock_client, &remote_conn_details_notif_len, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (remote_conn_details_notif_len <= 0 || remote_conn_details_notif_len >= (size_t)-1) {
		DOCA_LOG_ERR("Received wrong remote connection details");
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	remote_conn_details_notif = calloc(1, remote_conn_details_notif_len);
	if (remote_conn_details_notif == NULL) {
		DOCA_LOG_ERR("Failed to allocate memory for remote notif details %zd",
				remote_conn_details_notif_len);
		result = DOCA_ERROR_NO_MEMORY;
		return NIXL_ERR_BACKEND;
	}

	if (recv(oob_sock_client, remote_conn_details_notif, remote_conn_details_notif_len, 0) < 0) {
		DOCA_LOG_ERR("Failed to receive remote connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	//Data QP
	if (send(oob_sock_client, &rdma_qp->conn_det_len_data, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (send(oob_sock_client, rdma_qp->connection_details_data, rdma_qp->conn_det_len_data, 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	//Notif QP
	if (send(oob_sock_client, &rdma_qp->conn_det_len_notif, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	if (send(oob_sock_client, rdma_qp->connection_details_notif, rdma_qp->conn_det_len_notif, 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		result = DOCA_ERROR_CONNECTION_ABORTED;
		return NIXL_ERR_BACKEND;
	}

	/* Connect local rdma to the remote rdma */
	DOCA_LOG_INFO("Connect DOCA RDMA to remote RDMA -- data");
	result = doca_rdma_connect(rdma_qp->rdma_data, remote_conn_details_data, remote_conn_details_data_len, rdma_qp->connection_data);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Function doca_rdma_connect failed: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	free(remote_conn_details_data);
	remote_conn_details_data = NULL;

	/* Connect local rdma to the remote rdma */
	DOCA_LOG_INFO("Connect DOCA RDMA to remote RDMA -- notif");
	result = doca_rdma_connect(rdma_qp->rdma_notif, remote_conn_details_notif, remote_conn_details_notif_len, rdma_qp->connection_notif);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Function doca_rdma_connect failed: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	free(remote_conn_details_notif);
	remote_conn_details_notif = NULL;

	return NIXL_SUCCESS;
}

/****************************************
 * Constructor/Destructor
*****************************************/

nixlDocaEngine::nixlDocaEngine (const nixlBackendInitParams* init_params)
: nixlBackendEngine (init_params)
{
	std::vector<std::string> ndevs, tmp_gdevs; /* Empty vector */
	doca_error_t result;
	nixl_b_params_t* custom_params = init_params->customParams;

	result = doca_log_backend_create_standard();
	if (result != DOCA_SUCCESS)
		throw std::invalid_argument("Can't initialize doca log");

	result = doca_log_backend_create_with_file_sdk(stderr, &sdk_log);
	if (result != DOCA_SUCCESS)
		throw std::invalid_argument("Can't initialize doca log");

	result = doca_log_backend_set_sdk_level(sdk_log, DOCA_LOG_LEVEL_ERROR);
	if (result != DOCA_SUCCESS)
		throw std::invalid_argument("Can't initialize doca log");

	if (custom_params->count("network_devices") !=0 )
		ndevs = str_split((*custom_params)["network_devices"], " ");
	// Temporary: will extend to more NICs in a dedicated PR
	if (ndevs.size() > 1)
		throw std::invalid_argument("Only 1 network device is allowed");

	std::cout << "DOCA network devices:" << std::endl;
	for (const std::string& str : ndevs) {
		std::cout << str << " ";
	}
	std::cout << std::endl;

	if (custom_params->count("gpu_devices") == 0)
		throw std::invalid_argument("At least 1 GPU device must be specified");
	// Temporary: will extend to more GPUs in a dedicated PR
	if (custom_params->count("gpu_devices") > 1)
		throw std::invalid_argument("Only 1 GPU device is allowed");

	std::cout << "DOCA GPU devices:" << std::endl;
	tmp_gdevs = str_split((*custom_params)["gpu_devices"], " ");
	for (auto &cuda_id : tmp_gdevs) {
		gdevs.push_back(std::pair((uint32_t)std::stoi(cuda_id), nullptr));
		std::cout << "cuda_id " << cuda_id << "\n";
	}
	std::cout << std::endl;

	/* Open DOCA device */
	result = open_doca_device_with_ibdev_name((const uint8_t *)(ndevs[0].c_str()),
						  ndevs[0].size(),
						  &(ddev));
	if (result != DOCA_SUCCESS) {
		throw std::invalid_argument("Failed to open DOCA device");
	}

	char pciBusId[DOCA_DEVINFO_IBDEV_NAME_SIZE];
	for (auto &item : gdevs) {
		cudaDeviceGetPCIBusId(pciBusId, DOCA_DEVINFO_IBDEV_NAME_SIZE, item.first);
		result = doca_gpu_create(pciBusId, &item.second);
		if (result != DOCA_SUCCESS) {
			DOCA_LOG_ERR("Failed to create DOCA GPU device: %s", doca_error_get_descr(result));
		}
	}

	doca_devinfo_get_ipv4_addr(doca_dev_as_devinfo(ddev),
						    (uint8_t *)ipv4_addr,
						    DOCA_DEVINFO_IPV4_ADDR_SIZE);

	//GDRCopy
	result = doca_gpu_mem_alloc(gdevs[0].second, sizeof(struct docaXferReqGpu) * DOCA_XFER_REQ_MAX,
		4096,
		DOCA_GPU_MEM_TYPE_GPU_CPU,
		(void **)&xferReqRingGpu,
		(void **)&xferReqRingCpu);
	if (result != DOCA_SUCCESS || xferReqRingGpu == NULL || xferReqRingCpu == NULL) {
		DOCA_LOG_ERR("Function doca_gpu_mem_alloc returned %s", doca_error_get_descr(result));
	}

	nixlDocaEngineCheckCudaError(cudaMemset(xferReqRingGpu, 0, sizeof(struct docaXferReqGpu) * DOCA_XFER_REQ_MAX), "Failed to memset GPU memory");

	result = doca_gpu_mem_alloc(gdevs[0].second, sizeof(uint32_t) * 2,
		4096,
		DOCA_GPU_MEM_TYPE_GPU,
		(void **)&last_flags,
		nullptr);
	if (result != DOCA_SUCCESS || last_flags == NULL || last_flags == NULL) {
		DOCA_LOG_ERR("Function doca_gpu_mem_alloc returned %s", doca_error_get_descr(result));
	}

	nixlDocaEngineCheckCudaError(cudaMemset(last_flags, 0, sizeof(uint32_t) * 2), "Failed to memset GPU memory");

	nixlDocaEngineCheckCudaError(cudaStreamCreateWithFlags(&wait_stream, cudaStreamNonBlocking), "Failed to create CUDA stream");
	for (int i = 0; i < DOCA_POST_STREAM_NUM; i++)
		nixlDocaEngineCheckCudaError(cudaStreamCreateWithFlags(&post_stream[i], cudaStreamNonBlocking), "Failed to create CUDA stream");
	xferStream = 0;

	result = doca_gpu_mem_alloc(gdevs[0].second, sizeof(struct docaXferCompletion) * DOCA_MAX_COMPLETION_INFLIGHT,
		4096,
		DOCA_GPU_MEM_TYPE_CPU_GPU,
		(void **)&completion_list_gpu,
		(void **)&completion_list_cpu);
	if (result != DOCA_SUCCESS || completion_list_gpu == NULL || completion_list_cpu == NULL) {
		DOCA_LOG_ERR("Function doca_gpu_mem_alloc returned %s", doca_error_get_descr(result));
	}

	result = doca_gpu_mem_alloc(gdevs[0].second, sizeof(uint32_t),
		4096,
		DOCA_GPU_MEM_TYPE_GPU_CPU,
		(void **)&wait_exit_gpu,
		(void **)&wait_exit_cpu);
	if (result != DOCA_SUCCESS || wait_exit_gpu == NULL || wait_exit_cpu == NULL) {
		DOCA_LOG_ERR("Function doca_gpu_mem_alloc returned %s", doca_error_get_descr(result));
	}

	((volatile uint8_t *)wait_exit_cpu)[0] = 0;

	result = doca_gpu_mem_alloc(gdevs[0].second, sizeof(struct docaNotifRecv) * 1,
		4096,
		DOCA_GPU_MEM_TYPE_CPU_GPU,
		(void **)&notif_fill_gpu,
		(void **)&notif_fill_cpu);
	if (result != DOCA_SUCCESS || notif_fill_gpu == NULL || notif_fill_cpu == NULL) {
		DOCA_LOG_ERR("Function doca_gpu_mem_alloc returned %s", doca_error_get_descr(result));
	}

	result = doca_gpu_mem_alloc(gdevs[0].second, sizeof(struct docaNotifRecv) * 1,
		4096,
		DOCA_GPU_MEM_TYPE_CPU_GPU,
		(void **)&notif_progress_gpu,
		(void **)&notif_progress_cpu);
	if (result != DOCA_SUCCESS || notif_progress_gpu == NULL || notif_progress_cpu == NULL) {
		DOCA_LOG_ERR("Function doca_gpu_mem_alloc returned %s", doca_error_get_descr(result));
	}

	cuCtxGetCurrent(&main_cuda_ctx);
	printf("main main_cuda_ctx %p\n", (void*)main_cuda_ctx);
	//Warmup
	doca_kernel_progress(wait_stream, nullptr, notif_fill_gpu, notif_progress_gpu, wait_exit_gpu);
	cudaStreamSynchronize(wait_stream);
	doca_kernel_progress(wait_stream, completion_list_gpu, notif_fill_gpu, notif_progress_gpu, wait_exit_gpu);

	// We may need a GPU warmup with relevant DOCA engine kernels
	doca_kernel_write(0, nullptr, nullptr, 0);
	doca_kernel_read(0, nullptr, nullptr, 0);

	lastPostedReq = 0;
	xferRingPos = 0;
	firstXferRingPos = 0;

	progressThreadStart();
}

nixl_mem_list_t nixlDocaEngine::getSupportedMems () const {
	nixl_mem_list_t mems;
	mems.push_back(DRAM_SEG);
	mems.push_back(VRAM_SEG);
	return mems;
}

nixlDocaEngine::~nixlDocaEngine ()
{
	doca_error_t result;

	// per registered memory deregisters it, which removes the corresponding metadata too
	// parent destructor takes care of the desc list
	// For remote metadata, they should be removed here
	if (this->initErr) {
		// Nothing to do
		return;
	}

	//Cause accept in thread to fail and thus exit
	oob_connection_server_close(oob_sock_server);
	oob_connection_client_close(oob_sock_client);
	progressThreadStop();

	((volatile uint8_t *)wait_exit_cpu)[0] = 1;
	cudaStreamSynchronize(wait_stream);
	cudaStreamDestroy(wait_stream);
	DOCA_LOG_ERR("free wait_exit_gpu");
	doca_gpu_mem_free(gdevs[0].second, wait_exit_gpu);
	DOCA_LOG_ERR("free xferReqRingGpu");
	doca_gpu_mem_free(gdevs[0].second, xferReqRingGpu);
	DOCA_LOG_ERR("free last_flags");
	doca_gpu_mem_free(gdevs[0].second, last_flags);

	DOCA_LOG_ERR("free post_stream");
	for (int i = 0; i < DOCA_POST_STREAM_NUM; i++) {
		cudaStreamSynchronize(post_stream[i]);
		cudaStreamDestroy(post_stream[i]);
	}

	DOCA_LOG_ERR("free notifListv");
	for (auto notif : notifMap)
		nixlDocaDestroyNotif(gdevs[0].second, notif.second);

	doca_gpu_mem_free(gdevs[0].second, notif_fill_gpu);
	doca_gpu_mem_free(gdevs[0].second, notif_progress_gpu);

	DOCA_LOG_ERR("free completion_list_gpu");
	doca_gpu_mem_free(gdevs[0].second, completion_list_gpu);

	for (const auto& rdma_qp : qpMap) {
		DOCA_LOG_ERR("free rdma");
		result = doca_ctx_stop(rdma_qp.second->rdma_ctx_data);
		if (result != DOCA_SUCCESS)
			DOCA_LOG_ERR("Failed to stop RDMA context: %s", doca_error_get_descr(result));

		result = doca_rdma_destroy(rdma_qp.second->rdma_data);
		if (result != DOCA_SUCCESS)
			DOCA_LOG_ERR("Failed to destroy DOCA RDMA: %s", doca_error_get_descr(result));
    }

	result = doca_dev_close(ddev);
	if (result != DOCA_SUCCESS)
		DOCA_LOG_ERR("Failed to close DOCA device: %s", doca_error_get_descr(result));

	result = doca_gpu_destroy(gdevs[0].second);
	if (result != DOCA_SUCCESS)
		DOCA_LOG_ERR("Failed to close DOCA GPU device: %s", doca_error_get_descr(result));

}

/****************************************
 * Connection management
*****************************************/

nixl_status_t nixlDocaEngine::getConnInfo(std::string &str) const {
	std::stringstream ss;
    ss << (int)ipv4_addr[0] << "." << (int)ipv4_addr[1] << "." << (int)ipv4_addr[2] << "." << (int)ipv4_addr[3];
    str = ss.str();
	// str = nixlSerDes::_bytesToString(ipv4_addr, 4); //connection_details, conn_det_len);
	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::connect(const std::string &remote_agent) {
	/* Already connected to remote QP at loadRemoteConnInfo time */
	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::disconnect(const std::string &remote_agent) {
	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::loadRemoteConnInfo(const std::string &remote_agent, const std::string &remote_conn_info)
{
	// doca_error_t result;
	nixlDocaConnection conn;
	size_t size = remote_conn_info.size();
	//TODO: eventually std::byte?
	char* addr = new char[size];
	size_t ragent_size = remote_agent.size();

	if(remoteConnMap.find(remote_agent) != remoteConnMap.end()) {
		return NIXL_ERR_INVALID_PARAM;
	}

	nixlSerDes::_stringToBytes((void*) addr, remote_conn_info, size);

	printf("loadRemoteConnInfo -- client\n");
	int ret = oob_connection_client_setup(addr, &oob_sock_client);
	if (ret < 0) {
		DOCA_LOG_ERR("Can't connect to server %d", ret);
		return NIXL_ERR_BACKEND;
	}

	//Msg
	if (send(oob_sock_client, &ragent_size, sizeof(size_t), 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		return NIXL_ERR_BACKEND;
	}
	
	if (send(oob_sock_client, remote_agent.c_str(), remote_agent.size(), 0) < 0) {
		DOCA_LOG_ERR("Failed to send connection details");
		return NIXL_ERR_BACKEND;
	}

	addRdmaQp(remote_agent);
	nixlDocaInitNotif(remote_agent, ddev, gdevs[0].second);
	connectClientRdmaQp(oob_sock_client, remote_agent);
	conn.remoteAgent = remote_agent;
	conn.connected = true;

	std::cout << "Connected agent " << remote_agent << "\n";
	remoteConnMap[remote_agent] = conn;

	delete[] addr;

	return NIXL_SUCCESS;
}

/****************************************
 * Memory management
*****************************************/
nixl_status_t nixlDocaEngine::registerMem(const nixlBlobDesc &mem,
										  const nixl_mem_t &nixl_mem,
										  nixlBackendMD* &out)
{
	nixlDocaPrivateMetadata *priv = new nixlDocaPrivateMetadata;
	uint32_t permissions = DOCA_ACCESS_FLAG_LOCAL_READ_WRITE | DOCA_ACCESS_FLAG_RDMA_WRITE | DOCA_ACCESS_FLAG_PCI_RELAXED_ORDERING;
	doca_error_t result;

	auto it = std::find_if(gdevs.begin(), gdevs.end(),
							[&mem](std::pair<uint32_t, struct doca_gpu*> &x)
							{ return x.first == mem.devId; }
						);
	if (it == gdevs.end()) {
		std::cout << "Can't register memory for unknown device " << mem.devId << std::endl;
		return NIXL_ERR_INVALID_PARAM;
	}

	result = doca_mmap_create(&(priv->mem.mmap));
	if (result != DOCA_SUCCESS)
		return NIXL_ERR_BACKEND;

	result = doca_mmap_set_permissions(priv->mem.mmap, permissions);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_mmap_set_memrange(priv->mem.mmap, (void*)mem.addr, (size_t)mem.len);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_mmap_add_dev(priv->mem.mmap, ddev);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_mmap_start(priv->mem.mmap);
	if (result != DOCA_SUCCESS)
		goto error;

	/* export mmap for rdma */
	result = doca_mmap_export_rdma(priv->mem.mmap,
						ddev,
						(const void **)&(priv->mem.export_mmap),
						&(priv->mem.export_len));
	if (result != DOCA_SUCCESS)
		goto error;

	priv->mem.addr = (void*)mem.addr;
	priv->mem.len = mem.len;
	priv->mem.devId = mem.devId;
	priv->remoteMmapStr = nixlSerDes::_bytesToString((void*) priv->mem.export_mmap, priv->mem.export_len);

	/* Local buffer array */
	result = doca_buf_arr_create(1, &(priv->mem.barr));
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_set_params(priv->mem.barr, priv->mem.mmap, (size_t)mem.len, 0);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_set_target_gpu(priv->mem.barr, gdevs[mem.devId].second);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_start(priv->mem.barr);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_get_gpu_handle(priv->mem.barr, &(priv->mem.barr_gpu));
	if (result != DOCA_SUCCESS)
		goto error;

	out = (nixlBackendMD*) priv; //typecast?

	return NIXL_SUCCESS;

error:
	if (priv->mem.barr)
		doca_buf_arr_destroy(priv->mem.barr);

	if (priv->mem.mmap)
		doca_mmap_destroy(priv->mem.mmap);

	return NIXL_ERR_BACKEND;
}

nixl_status_t nixlDocaEngine::deregisterMem(nixlBackendMD* meta)
{
	doca_error_t result;
	nixlDocaPrivateMetadata *priv = (nixlDocaPrivateMetadata*) meta;

	result = doca_buf_arr_destroy(priv->mem.barr);
	if (result != DOCA_SUCCESS)
		DOCA_LOG_ERR("Failed to call doca_buf_arr_destroy: %s", doca_error_get_descr(result));

	result = doca_mmap_destroy(priv->mem.mmap);
	if (result != DOCA_SUCCESS)
		DOCA_LOG_ERR("Failed to call doca_mmap_destroy: %s", doca_error_get_descr(result));

	delete priv;
	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::getPublicData (const nixlBackendMD* meta,
											std::string &str) const {
	const nixlDocaPrivateMetadata *priv = (nixlDocaPrivateMetadata*) meta;
	str = priv->remoteMmapStr;
	return NIXL_SUCCESS;
}

nixl_status_t
nixlDocaEngine::internalMDHelper(const nixl_blob_t &blob,
								 const std::string &agent,
								 nixlBackendMD* &output)
{
	doca_error_t result;
	nixlDocaConnection conn;
	nixlDocaPublicMetadata *md = new nixlDocaPublicMetadata;
	size_t size = blob.size();
	auto search = remoteConnMap.find(agent);

	if(search == remoteConnMap.end()) {
		//TODO: err: remote connection not found
		DOCA_LOG_ERR("err: remote connection not found");
		return NIXL_ERR_NOT_FOUND;
	}
	conn = (nixlDocaConnection) search->second;

	//directly copy underlying conn struct
	md->conn = conn;

	char *addr = new char[size];
	nixlSerDes::_stringToBytes(addr, blob, size);

	result = doca_mmap_create_from_export(NULL,
		addr,
		size,
		ddev,
		&md->mem.mmap);
	if (result != DOCA_SUCCESS) {
		DOCA_LOG_ERR("Function doca_mmap_create_from_export failed: %s", doca_error_get_descr(result));
		return NIXL_ERR_BACKEND;
	}

	/* Remote buffer array */
	result = doca_buf_arr_create(1, &(md->mem.barr));
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_set_params(md->mem.barr, md->mem.mmap, size, 0);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_set_target_gpu(md->mem.barr, gdevs[0].second);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_start(md->mem.barr);
	if (result != DOCA_SUCCESS)
		goto error;

	result = doca_buf_arr_get_gpu_handle(md->mem.barr, &(md->mem.barr_gpu));
	if (result != DOCA_SUCCESS)
		goto error;

	output = (nixlBackendMD*) md;

	// printf("Remote MMAP created %p raddr %p size %zd\n", (void*)md->mem.mmap, (void*)addr, size);

	delete[] addr;

	return NIXL_SUCCESS;

error:
	if (md->mem.barr)
		doca_buf_arr_destroy(md->mem.barr);

	return NIXL_ERR_BACKEND;
}

nixl_status_t
nixlDocaEngine::loadLocalMD (nixlBackendMD* input,
							nixlBackendMD* &output)
{
	/* supportsLocal == false. Should it be true? */
	// nixlDocaPrivateMetadata* input_md = (nixlDocaPrivateMetadata*) input;
	// return internalMDHelper(input_md->remoteMmapStr, localAgent, output);

	return NIXL_SUCCESS;
}

// To be cleaned up
nixl_status_t nixlDocaEngine::loadRemoteMD (const nixlBlobDesc &input,
										   const nixl_mem_t &nixl_mem,
										   const std::string &remote_agent,
										   nixlBackendMD* &output)
{
	return internalMDHelper(input.metaInfo, remote_agent, output);
}

nixl_status_t nixlDocaEngine::unloadMD (nixlBackendMD* input) {
	return NIXL_SUCCESS;
}

/****************************************
 * Data movement
*****************************************/
nixl_status_t nixlDocaEngine::prepXfer (const nixl_xfer_op_t &operation,
									   const nixl_meta_dlist_t &local,
									   const nixl_meta_dlist_t &remote,
									   const std::string &remote_agent,
									   nixlBackendReqH* &handle,
									   const nixl_opt_b_args_t* opt_args)
{
	uint32_t pos;
	nixlDocaBckndReq *treq = new nixlDocaBckndReq;
	nixlDocaPrivateMetadata *lmd;
	nixlDocaPublicMetadata *rmd;
	uint32_t lcnt = (uint32_t)local.descCount();
	uint32_t rcnt = (uint32_t)remote.descCount();
	uint32_t stream_id;
	struct nixlDocaRdmaQp *rdma_qp;

	// check device id from local dlist mr that should be all the same and same of the engine
	for (uint32_t idx = 0; idx < lcnt; idx++) {
		lmd = (nixlDocaPrivateMetadata*) local[idx].metadataP;
		if (lmd->mem.devId != gdevs[0].first)
			return NIXL_ERR_INVALID_PARAM;
	}

	if(qpMap.find(remote_agent) == qpMap.end()) {
		std::cout << "Can't find remote_agent " << remote_agent << "\n";
		return NIXL_ERR_INVALID_PARAM;
	}

	rdma_qp = qpMap[remote_agent];

	if (lcnt != rcnt)
		return NIXL_ERR_INVALID_PARAM;

	if (lcnt == 0)
		return NIXL_ERR_INVALID_PARAM;

	if (opt_args->gpuInitiated) {
		if (lcnt > DOCA_XFER_REQ_SIZE || rcnt > DOCA_XFER_REQ_SIZE)
		return NIXL_ERR_INVALID_PARAM;

		treq->start_pos = (xferRingPos.fetch_add(1) & (DOCA_XFER_REQ_MAX - 1));

		for (uint32_t idx = 0; idx < lcnt && idx < DOCA_XFER_REQ_SIZE; idx++) {
			size_t lsize = local[idx].len;
			size_t rsize = remote[idx].len;
			if (lsize != rsize)
				return NIXL_ERR_INVALID_PARAM;

			lmd = (nixlDocaPrivateMetadata*) local[idx].metadataP;
			rmd = (nixlDocaPublicMetadata*) remote[idx].metadataP;

			xferReqRingCpu[treq->start_pos].larr[idx] = (uintptr_t)lmd->mem.barr_gpu;
			xferReqRingCpu[treq->start_pos].rarr[idx] = (uintptr_t)rmd->mem.barr_gpu;
			xferReqRingCpu[treq->start_pos].size[idx] = lsize;
			xferReqRingCpu[treq->start_pos].backendOp = operation;
			xferReqRingCpu[treq->start_pos].rdma_gpu_data = rdma_qp->rdma_gpu_data;
			xferReqRingCpu[treq->start_pos].rdma_gpu_notif = rdma_qp->rdma_gpu_notif;
			xferReqRingCpu[treq->start_pos].num++;
		}
		//Only 1 struct for device mode
		treq->end_pos = treq->start_pos;

		treq->backendHandleGpu = (uintptr_t)(xferReqRingGpu + treq->start_pos);
		handle = treq;
	} else {

		std::cout << " extra params " << opt_args->customParam;

		if (opt_args->customParam.empty()) {
			stream_id = (xferStream.fetch_add(1) & (DOCA_POST_STREAM_NUM - 1));
			printf("xferCreate no stream, taking the next one %d\n", stream_id);
			treq->stream = post_stream[stream_id];
		} else {
			treq->stream = (cudaStream_t)*((uintptr_t *)opt_args->customParam.data());
			printf("xferCreate stream %lx\n", (uintptr_t)treq->stream);
		}

		#if 0
			auto it = std::find_if(gdevs.begin(), gdevs.end(),
					[&treq](std::pair<uint32_t, struct doca_gpu*> &x)
					{ return x.first == treq->devId; }
				);
			if (it == gdevs.end()) {
				std::cout << "Can't prepare transfer for unknown device " << treq->devId << std::endl;
				return NIXL_ERR_INVALID_PARAM;
			}
		#endif

		treq->start_pos = (xferRingPos.fetch_add(1) & (DOCA_XFER_REQ_MAX - 1));
		pos = treq->start_pos;

		do {
			for (uint32_t idx = 0; idx < lcnt && idx < DOCA_XFER_REQ_SIZE; idx++) {
				size_t lsize = local[idx].len;
				size_t rsize = remote[idx].len;
				if (lsize != rsize)
					return NIXL_ERR_INVALID_PARAM;

				lmd = (nixlDocaPrivateMetadata*) local[idx].metadataP;
				rmd = (nixlDocaPublicMetadata*) remote[idx].metadataP;

				xferReqRingCpu[pos].larr[idx] = (uintptr_t)lmd->mem.barr_gpu;
				xferReqRingCpu[pos].rarr[idx] = (uintptr_t)rmd->mem.barr_gpu;
				xferReqRingCpu[pos].size[idx] = lsize;
				xferReqRingCpu[pos].num++;
			}

			xferReqRingCpu[pos].last_rsvd = last_flags;
			xferReqRingCpu[pos].last_posted = last_flags + 1;
			xferReqRingCpu[pos].rdma_gpu_data = rdma_qp->rdma_gpu_data;
			xferReqRingCpu[pos].rdma_gpu_notif = rdma_qp->rdma_gpu_notif;

			if (lcnt > DOCA_XFER_REQ_SIZE) {
				lcnt -= DOCA_XFER_REQ_SIZE;
				pos = (xferRingPos.fetch_add(1) & (DOCA_XFER_REQ_MAX - 1));
			} else {
				lcnt = 0;
			}
		} while(lcnt > 0);

		treq->end_pos = xferRingPos;

		if (opt_args && opt_args->hasNotif) {
			if(notifMap.find(remote_agent) == notifMap.end()) {
				std::cout << "Can't find notif for remote_agent " << remote_agent << "\n";
				return NIXL_ERR_INVALID_PARAM;
			}

			struct nixlDocaNotif *notif = notifMap[remote_agent];
			//Checl notifMsg size
			std::string newMsg = msg_tag + opt_args->notifMsg;
			xferReqRingCpu[treq->end_pos-1].has_notif_msg_idx = (notif->send_pi.fetch_add(1) & (notif->elems_num - 1));
			xferReqRingCpu[treq->end_pos-1].notif_barr_gpu = notif->send_barr_gpu;

			printf("HAS NOTIF pos %d - %s\n", treq->end_pos-1, newMsg.c_str());

			memcpy(notif->send_addr + (xferReqRingCpu[treq->end_pos-1].has_notif_msg_idx * notif->elems_size),
					newMsg.c_str(),
					newMsg.size());
		} else {
			xferReqRingCpu[treq->end_pos-1].has_notif_msg_idx = DOCA_NOTIF_NULL;
		}

		treq->backendHandleGpu = 0;

		handle = treq;
	}

	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::postXfer (const nixl_xfer_op_t &operation,
									   const nixl_meta_dlist_t &local,
									   const nixl_meta_dlist_t &remote,
									   const std::string &remote_agent,
									   nixlBackendReqH* &handle,
									   const nixl_opt_b_args_t* opt_args)
{
	nixlDocaBckndReq *treq = (nixlDocaBckndReq *) handle;

	std::cout << "postXfer start " << treq->start_pos << " end " << treq->end_pos
				<< " opt_args->hasNotif " << opt_args->hasNotif
				<< " opt_args->notifMsg " << opt_args->notifMsg
				<< " opt_args->notifMsg size " << opt_args->notifMsg.size()
				<< "\n";

	for (uint32_t idx = treq->start_pos; idx < treq->end_pos; idx++) {
		xferReqRingCpu[idx].id = (lastPostedReq.fetch_add(1) & (DOCA_MAX_COMPLETION_INFLIGHT - 1));
		completion_list_cpu[xferReqRingCpu[idx].id].xferReqRingGpu = xferReqRingGpu + idx;
		completion_list_cpu[xferReqRingCpu[idx].id].completed = 0;

		printf("Completion list idx %d id %d\n", idx, xferReqRingCpu[idx].id);

		switch (operation) {
			case NIXL_READ:
				// std::cout << "READ KERNEL, pos " << idx << " num " << xferReqRingCpu[idx].num << "\n";
				doca_kernel_read(treq->stream, xferReqRingCpu[idx].rdma_gpu_data, xferReqRingGpu, idx);
				break;
			case NIXL_WRITE:
				std::cout << "WRITE KERNEL, pos " << idx << " num " << xferReqRingCpu[idx].num << "\n";
				doca_kernel_write(treq->stream, xferReqRingCpu[idx].rdma_gpu_data, xferReqRingGpu, idx);
				break;
			default:
				return NIXL_ERR_INVALID_PARAM;
		}
	}

	return NIXL_IN_PROG;
}

nixl_status_t nixlDocaEngine::checkXfer(nixlBackendReqH* handle)
{
	nixlDocaBckndReq *treq = (nixlDocaBckndReq *) handle;
	uint32_t completion_index;

	for (uint32_t idx = treq->start_pos; idx < treq->end_pos; idx++) {
		completion_index = xferReqRingCpu[idx].id & (DOCA_MAX_COMPLETION_INFLIGHT - 1);

		if (((volatile docaXferCompletion *)completion_list_cpu)[completion_index].completed == 1) {
			xferReqRingCpu[idx].in_use = 0;
			return NIXL_SUCCESS;
		} else
			return NIXL_IN_PROG;
	}

	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::getGpuXferH(const nixlBackendReqH* handle, nixlXferReqHGpu* &gpu_hndl)
{
	nixlDocaBckndReq *treq = (nixlDocaBckndReq *) handle;
	nixlXferReqHGpu* tmp = new nixlXferReqHGpu;

	if (treq->backendHandleGpu == 0)
		return NIXL_ERR_NOT_SUPPORTED;

	*tmp = treq->backendHandleGpu;
	gpu_hndl = tmp;

	return NIXL_SUCCESS;
}


nixl_status_t nixlDocaEngine::releaseReqH(nixlBackendReqH* handle)
{
	firstXferRingPos = xferRingPos & (DOCA_XFER_REQ_MAX - 1);

	return NIXL_SUCCESS;
}

int nixlDocaEngine::progress() {
	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::getNotifs(notif_list_t &notif_list)
{
	uint32_t tmp;
	std::string msg_out;

	for (auto notif : notifMap) {
		do {
			tmp = notif.second->recv_pi;
			msg_out = (char*)(notif.second->recv_addr + (tmp * notif.second->elems_size));
			size_t position = msg_out.find(msg_tag);
			if (position != std::string::npos && position == 0) {
				std::string msg = msg_out.substr(msg_tag.size(), DOCA_MAX_NOTIF_MESSAGE_SIZE-msg_tag.size()); //msg_c;
				notif_list.push_back(std::pair(notif.first, msg));
				msg_out.replace(0, msg_tag.size(), "0000");
				//progress
				notif.second->recv_pi.fetch_add(1);
			} else 
				break;
		} while (1);
	}

	return NIXL_SUCCESS;
}

nixl_status_t nixlDocaEngine::genNotif(const std::string &remote_agent, const std::string &msg)
{
	nixl_status_t ret = NIXL_SUCCESS;
	// ret = notifSendPriv(remote_agent, msg, req);

	switch(ret) {
	case NIXL_IN_PROG:
		/* do not track the request */
		// uw->reqRelease(req);
	case NIXL_SUCCESS:
		break;
	default:
		/* error case */
		return ret;
	}
	return NIXL_SUCCESS;
}
